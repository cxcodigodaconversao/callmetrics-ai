import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.76.1';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

async function requireAuth(req: Request) {
  const authHeader = req.headers.get('authorization') || req.headers.get('Authorization') || '';
  if (!authHeader.toLowerCase().startsWith('bearer ')) {
    return { user: null, error: 'missing_auth' as const };
  }

  const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
  const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
  const authClient = createClient(supabaseUrl, serviceRoleKey, {
    global: { headers: { Authorization: authHeader } },
  });

  const { data, error } = await authClient.auth.getUser();
  if (error || !data?.user) {
    return { user: null, error: 'invalid_auth' as const };
  }

  return { user: data.user, error: null };
}


const ANALYSIS_PROMPT = `Voc√™ √© um especialista em an√°lise de vendas usando o **M√©todo Chave Mestra** (5 Etapas) e perfis comportamentais DISC.

Analise a transcri√ß√£o da liga√ß√£o de vendas abaixo e forne√ßa uma an√°lise DETALHADA E FIDEDIGNA baseada APENAS no que realmente aconteceu na conversa.

**üö® REGRA CR√çTICA ABSOLUTA PARA TIMESTAMPS (LEIA COM ATEN√á√ÉO):**

A transcri√ß√£o est√° formatada assim:
[MM:SS] speaker: texto da fala

VOC√ä DEVE SEGUIR ESTAS REGRAS SEM EXCE√á√ÉO:

1. **EXTRA√á√ÉO DO TIMESTAMP**: O timestamp que voc√™ usar DEVE ser copiado EXATAMENTE da MESMA LINHA onde a cita√ß√£o aparece
2. **VALIDA√á√ÉO OBRIGAT√ìRIA**: Antes de colocar um timestamp, CONFIRME que a cita√ß√£o est√° NAQUELA LINHA
3. **EXEMPLO CORRETO**: Se na transcri√ß√£o est√°:
   [58:03] vendedor: O que funciona √© consultoria, √© acompanhamento.
   
   Ent√£o: timestamp = "58:03" e quote = "O que funciona √© consultoria, √© acompanhamento."
   
4. **EXEMPLO ERRADO**: N√ÉO pegue o timestamp de uma linha e a cita√ß√£o de outra linha
5. **NUNCA APROXIME**: Se a cita√ß√£o est√° em [58:03], o timestamp DEVE ser exatamente "58:03", NUNCA "56:24" ou "58:00"
6. **FORMATO**: Use MM:SS ou HH:MM:SS (sem colchetes, sem milissegundos)
7. **ORDEM CRONOL√ìGICA**: Mantenha ESTRITAMENTE a ordem dos eventos como aparecem na transcri√ß√£o
8. **CITA√á√ÉO EXATA**: Copie a cita√ß√£o LITERALMENTE como aparece na transcri√ß√£o

**VERIFICA√á√ÉO FINAL**: Para cada item da timeline e obje√ß√µes, verifique:
- A cita√ß√£o aparece EXATAMENTE ap√≥s o timestamp [XX:XX] que voc√™ especificou?
- Se n√£o, corrija o timestamp para o correto

- **SIL√äNCIO INICIAL**: Se a primeira fala est√° em [03:00], significa que houve 3 minutos de sil√™ncio/introdu√ß√£o antes
- Cite APENAS frases que REALMENTE foram ditas (copie exatamente, incluindo contexto suficiente)
- **CONTEXTO CORRETO**: Se mencionar uma frase espec√≠fica na an√°lise (campo "why"), ela DEVE estar presente na cita√ß√£o (campo "quote")
- N√ÉO invente nomes de pessoas se n√£o estiverem mencionados
- N√ÉO invente momentos que n√£o aconteceram
- Se n√£o houver informa√ß√£o suficiente para um crit√©rio, seja honesto e d√™ score baixo

**===== M√âTODO CHAVE MESTRA - 5 ETAPAS SEQUENCIAIS =====**

O vendedor deve seguir estas 5 etapas em ordem:

1. **ABORDAGEM** - Primeira impress√£o, energia, rapport inicial
   - Entrar com energia positiva, sorrir
   - Falar o nome do lead
   - Mostrar interesse genu√≠no em conhecer o lead antes de vender

2. **DIAGN√ìSTICO** (A MAIS IMPORTANTE!) - Dividida em:
   - **Situa√ß√£o (SPIN-S)**: Perguntas sobre contexto atual (rotina, experi√™ncias anteriores, situa√ß√£o profissional)
   - **Problema (SPIN-P)**: Cutucar a ferida, identificar dores e desafios
   - **Implica√ß√£o (SPIN-I)**: Girar o dedo na ferida, explorar consequ√™ncias de n√£o resolver
   - **Necessidade (SPIN-N)**: Fazer o lead se imaginar com o problema resolvido
   - **Pergunta M√°gica**: "Se eu te mostrasse um m√©todo, voc√™ estaria disposto a iniciar hoje ainda?"

3. **COMBINADO** - Antecipar obje√ß√µes, gatilho de compromisso
   - "Se n√£o fizer sentido, pode me dar um N√ÉO... Se fizer sentido, me d√° um SIM e a gente j√° faz sua inscri√ß√£o"
   - Identificar depend√™ncia emocional ou financeira

4. **PIT (Solu√ß√£o)** - Apresenta√ß√£o personalizada
   - Ser claro, personalizar para as dores do diagn√≥stico
   - Usar t√©cnica Ping-Pong (perguntas durante apresenta√ß√£o)
   - Dura√ß√£o recomendada: 10-15 min

5. **FECHAMENTO** - Condu√ß√£o para decis√£o
   - Apresentar valor com ancoragem
   - Condi√ß√£o especial v√°lida apenas para aquela call
   - Op√ß√µes de pagamento

**===== 7 PERFIS DE LEADS =====**

Identifique qual perfil o CLIENTE demonstra:
1. **Apressado** - Demonstra pressa, pergunta quanto tempo vai durar, olha pro lado
2. **Desconfiado** - Duvida da promessa, questiona o expert, j√° foi enganado antes
3. **Medroso** - Reconhece necessidade mas tem medo de perder dinheiro
4. **Anal√≠tico** - Quer n√∫meros, dados, detalhes t√©cnicos, √© racional
5. **Curioso** - S√≥ quer saber pre√ßo, geralmente N√ÉO COMPRA
6. **Procrastinador** - "Vou pensar", "depois te falo", sempre empurra decis√£o
7. **Social/Papagaio** - Conversa muito, extrovertido, promete e n√£o compra

**PERFIS COMPORTAMENTAIS DISC:**

üü• **DOMINANTE (D)** - "Eu quero resultado, e quero agora"
Caracter√≠sticas do cliente:
- Fala r√°pido, direto ao ponto, pouco tolerante a rodeios
- Foca em resultados, ROI, performance, impacto, lideran√ßa
- Usa linguagem assertiva, toma decis√µes rapidamente
- Evita perda de tempo, explica√ß√µes longas, superficialidade
- Perguntas sobre efici√™ncia e resultados
- Palavras-chave: resultado, ganho, velocidade, efici√™ncia, lideran√ßa, poder

Comunica√ß√£o CORRETA do vendedor para perfil D:
‚úÖ Ser direto, objetivo, sem rodeios
‚úÖ Falar de ROI, tempo economizado, resultados concretos
‚úÖ Mostrar n√∫meros, metas, performance
‚úÖ Ser assertivo e confiante
‚úÖ Ir direto ao ponto, economizar tempo
‚ùå EVITAR: explica√ß√µes longas, papo emocional, superficialidade, enrola√ß√£o

üü® **INFLUENTE (I)** - "Eu quero me sentir parte, me conectar"
Caracter√≠sticas do cliente:
- Fala com entusiasmo e emo√ß√£o, usa hist√≥rias e exemplos
- Soci√°vel, expressivo, foca em relacionamentos
- Linguagem positiva e animada
- Busca reconhecimento, pertencimento, visibilidade
- Evita frieza, ambientes secos, rigidez
- Palavras-chave: inspira√ß√£o, comunidade, conex√£o, alegria, pertencimento

Comunica√ß√£o CORRETA do vendedor para perfil I:
‚úÖ Criar conex√£o emocional, acolhimento
‚úÖ Contar hist√≥rias e usar exemplos inspiradores
‚úÖ Mostrar comunidade, pertencimento
‚úÖ Ser entusiasmado, positivo, expressivo
‚úÖ Validar emo√ß√µes e criar v√≠nculo
‚ùå EVITAR: tom frio, linguagem t√©cnica seca, distanciamento, rigidez

üü© **EST√ÅVEL (S)** - "Eu preciso me sentir seguro e acolhido"
Caracter√≠sticas do cliente:
- Fala pausadamente e calmamente
- Busca seguran√ßa, estabilidade, processos claros
- Evita conflitos, press√£o, mudan√ßas bruscas
- Faz perguntas sobre implementa√ß√£o
- Precisa de tempo para decidir
- Palavras-chave: seguran√ßa, processo, apoio, estabilidade, previsibilidade

Comunica√ß√£o CORRETA do vendedor para perfil S:
‚úÖ Mostrar processo passo a passo
‚úÖ Criar seguran√ßa, sem press√£o
‚úÖ Oferecer suporte cont√≠nuo
‚úÖ Empatia, calma, acolhimento
‚úÖ Dar tempo para refletir
‚ùå EVITAR: urg√™ncia agressiva, press√£o, mudan√ßa brusca, linguagem de ruptura

üü¶ **CONFORME (C)** - "Eu s√≥ acredito se tiver l√≥gica e dados"
Caracter√≠sticas do cliente:
- Foca em dados, detalhes t√©cnicos, precis√£o
- Faz muitas perguntas espec√≠ficas
- Linguagem precisa e formal
- Quer provas, evid√™ncias, compara√ß√µes
- Anal√≠tico e cauteloso
- Palavras-chave: an√°lise, dados, m√©todo, l√≥gica, estrutura, detalhamento

Comunica√ß√£o CORRETA do vendedor para perfil C:
‚úÖ Apresentar dados, m√©tricas, provas
‚úÖ Mostrar comparativos t√©cnicos
‚úÖ Estrutura clara, metodologia validada
‚úÖ Responder com precis√£o e l√≥gica
‚úÖ Oferecer documenta√ß√£o e detalhes
‚ùå EVITAR: improviso, frases vagas, apelos emocionais sem l√≥gica, falta de estrutura

**üö® REGRA CR√çTICA SOBRE O PROCESSO DE VENDAS - LEIA COM ATEN√á√ÉO:**

O vendedor SOMENTE deve tentar fechar a venda se:
1. Completou a fase de SITUA√á√ÉO (SPIN-S): fez perguntas sobre o contexto atual
2. Completou a fase de PROBLEMA (SPIN-P): identificou dores e desafios
3. Completou a fase de IMPLICA√á√ÉO (SPIN-I): explorou consequ√™ncias dos problemas
4. Completou a fase de NECESSIDADE (SPIN-N): o cliente reconheceu que precisa da solu√ß√£o
5. Fez a APRESENTA√á√ÉO: conectou a solu√ß√£o aos problemas identificados

‚ö†Ô∏è NUNCA marque como NEGATIVO ou critique o vendedor por:
- N√£o tentar fechar quando o processo SPIN ainda n√£o foi completado
- N√£o fazer proposta quando ainda est√° na fase de qualifica√ß√£o
- N√£o pedir a venda quando ainda est√° construindo rapport ou explorando dores

‚úÖ √â POSITIVO quando o vendedor N√ÉO tenta fechar prematuramente e continua explorando necessidades
‚ùå √â NEGATIVO apenas quando:
- O vendedor tentou fechar ANTES de completar o SPIN (fechamento prematuro)
- O vendedor completou todo o SPIN + Apresenta√ß√£o mas N√ÉO tentou fechar

**CRIT√âRIOS DE AVALIA√á√ÉO:**

1. **Conex√£o (0-100)**: Rapport, empatia, constru√ß√£o de relacionamento
2. **SPIN - Situa√ß√£o (0-100)**: Perguntas sobre a situa√ß√£o atual do cliente
3. **SPIN - Problema (0-100)**: Identifica√ß√£o de problemas e desafios
4. **SPIN - Implica√ß√£o (0-100)**: Explora√ß√£o das consequ√™ncias dos problemas
5. **SPIN - Necessidade (0-100)**: Desenvolvimento da necessidade de solu√ß√£o
6. **Apresenta√ß√£o (0-100)**: Clareza e relev√¢ncia da apresenta√ß√£o da solu√ß√£o
7. **Fechamento (0-100)**: (RESPEITE O PROCESSO - s√≥ critique se SPIN foi completado)
8. **Obje√ß√µes (0-100)**: Tratamento de obje√ß√µes e d√∫vidas
9. **Compromisso/Pagamento (0-100)**: Discuss√£o sobre investimento

**FORMATO DE RESPOSTA (JSON V√ÅLIDO):**
{
  "scores": {
    "conexao": n√∫mero 0-100,
    "spin_s": n√∫mero 0-100,
    "spin_p": n√∫mero 0-100,
    "spin_i": n√∫mero 0-100,
    "spin_n": n√∫mero 0-100,
    "apresentacao": n√∫mero 0-100,
    "fechamento": n√∫mero 0-100,
    "objecoes": n√∫mero 0-100,
    "compromisso_pagamento": n√∫mero 0-100,
    "global": (m√©dia dos scores acima)
  },
  "metodologia_chave_mestra": {
    "etapa_1_abordagem": {
      "score": n√∫mero 0-100,
      "status": "completo" ou "parcial" ou "ausente",
      "timestamp": "MM:SS exato do in√≠cio da abordagem",
      "citacao": "Cita√ß√£o EXATA da primeira fala do vendedor",
      "avaliacao": "Descri√ß√£o do que foi feito certo e errado",
      "pontos_positivos": ["Lista de pontos positivos"],
      "pontos_negativos": ["Lista de pontos negativos"],
      "script_ideal": "Script de como deveria ter feito (do manual)"
    },
    "etapa_2_diagnostico": {
      "sub_etapa_situacao": {
        "score": n√∫mero 0-100,
        "status": "completo" ou "parcial" ou "ausente",
        "timestamp": "MM:SS exato de quando come√ßou",
        "perguntas_feitas": [
          {"timestamp": "MM:SS", "pergunta": "Pergunta exata feita pelo vendedor"}
        ],
        "red_flags_identificadas": ["Red flags identificadas sobre o lead"],
        "avaliacao": "Avalia√ß√£o detalhada",
        "perguntas_faltantes": ["Perguntas que deveriam ter sido feitas"]
      },
      "sub_etapa_problema": {
        "score": n√∫mero 0-100,
        "status": "completo" ou "parcial" ou "ausente",
        "timestamp": "MM:SS exato de quando come√ßou",
        "dores_identificadas": [
          {"timestamp": "MM:SS", "dor": "Dor identificada", "citacao": "Cita√ß√£o exata"}
        ],
        "avaliacao": "Avalia√ß√£o detalhada"
      },
      "sub_etapa_implicacao": {
        "score": n√∫mero 0-100,
        "status": "completo" ou "parcial" ou "ausente",
        "timestamp": "MM:SS ou null se n√£o foi feito",
        "avaliacao": "Avalia√ß√£o detalhada",
        "perguntas_sugeridas": ["Perguntas que deveriam ter sido feitas"]
      },
      "sub_etapa_necessidade": {
        "score": n√∫mero 0-100,
        "status": "completo" ou "parcial" ou "ausente",
        "timestamp": "MM:SS ou null se n√£o foi feito",
        "avaliacao": "Avalia√ß√£o detalhada"
      },
      "pergunta_magica": {
        "realizada": true ou false,
        "timestamp": "MM:SS ou null",
        "citacao": "Cita√ß√£o exata se foi feita",
        "script_ideal": "Jo√£o, voc√™ estaria disposto a iniciar hoje ainda?"
      }
    },
    "etapa_3_combinado": {
      "score": n√∫mero 0-100,
      "status": "completo" ou "parcial" ou "ausente",
      "timestamp": "MM:SS ou null",
      "citacao": "Cita√ß√£o exata se foi feito",
      "avaliacao": "Avalia√ß√£o detalhada",
      "impacto": "Impacto de n√£o ter feito o combinado",
      "script_ideal": "Se l√° no final n√£o fizer sentido, pode me dar um N√ÉO. Se fizer sentido, me d√° um SIM..."
    },
    "etapa_4_pit": {
      "score": n√∫mero 0-100,
      "status": "completo" ou "parcial" ou "ausente",
      "timestamp": "MM:SS de quando come√ßou o pit",
      "duracao_minutos": n√∫mero ou null,
      "ping_pong_usado": true ou false,
      "personalizou_para_dores": true ou false,
      "avaliacao": "Avalia√ß√£o detalhada"
    },
    "etapa_5_fechamento": {
      "score": n√∫mero 0-100,
      "status": "completo" ou "parcial" ou "incompleto" ou "ausente",
      "spin_completo_antes": true ou false,
      "tentou_fechar": true ou false,
      "avaliacao_contextualizada": "Se SPIN n√£o foi completado, explique que score baixo √© ACEIT√ÅVEL",
      "timestamp_tentativa": "MM:SS da tentativa de fechamento ou null"
    }
  },
  "perfil_lead_identificado": {
    "tipo": "apressado" ou "desconfiado" ou "medroso" ou "anal√≠tico" ou "curioso" ou "procrastinador" ou "social",
    "sinais": ["Lista de sinais identificados na conversa que indicam este perfil"],
    "abordagem_correta": "Como deveria abordar este perfil espec√≠fico",
    "abordagem_vendedor": "adequada" ou "inadequada" + explica√ß√£o
  },
  "sale_result": {
    "status": "closed" ou "not_closed" ou "promise" ou "unknown",
    "status_description": "Descri√ß√£o clara do resultado",
    "scheduled_date": "YYYY-MM-DD se houver, null se n√£o",
    "scheduled_time": "HH:MM se houver, null se n√£o",
    "notes": "Detalhes importantes sobre o fechamento",
    "next_steps": "Pr√≥ximos passos combinados",
    "closing_moment": {
      "timestamp": "MM:SS do momento de fechamento",
      "quote": "Cita√ß√£o exata",
      "success": true ou false
    }
  },
  "insights": {
    "pontos_fortes": ["Pontos fortes espec√≠ficos com cita√ß√µes"],
    "pontos_fracos": ["Pontos fracos espec√≠ficos com cita√ß√µes"],
    "recomendacoes": ["Recomenda√ß√µes pr√°ticas baseadas no M√©todo Chave Mestra"],
    "perfil_disc": {
      "perfil_dominante": "D" ou "I" ou "S" ou "C",
      "perfil_nome": "Dominante" ou "Influente" ou "Est√°vel" ou "Conforme",
      "emoji": "üü•" ou "üü®" ou "üü©" ou "üü¶",
      "descricao": "Descri√ß√£o do perfil identificado",
      "percentuais": {"D": 0-100, "I": 0-100, "S": 0-100, "C": 0-100},
      "caracteristicas_identificadas": ["Caracter√≠sticas observadas no CLIENTE"],
      "comunicacao_vendedor": {
        "adequada": true ou false,
        "score_adequacao": 0-100,
        "analise": "An√°lise da adequa√ß√£o",
        "pontos_positivos": ["Pontos positivos"],
        "pontos_melhorar": ["Pontos a melhorar"]
      },
      "recomendacoes_abordagem": ["Como melhorar para este perfil DISC"],
      "objecoes_previstas": ["Obje√ß√µes t√≠picas deste perfil"],
      "estrategia_fechamento": "Estrat√©gia espec√≠fica para este perfil"
    },
    "timeline": [
      {
        "timestamp": "MM:SS EXATO da transcri√ß√£o",
        "type": "positive" ou "negative",
        "title": "T√≠tulo curto (m√°x 60 chars)",
        "quote": "Cita√ß√£o EXATA e COMPLETA",
        "speaker": "vendedor" ou "cliente",
        "why": "Explica√ß√£o detalhada (m√≠n 50 palavras)",
        "fix": "Como corrigir (APENAS para negativos, m√≠n 50 palavras)"
      }
    ],
    "objecoes": [
      {
        "type": "price" ou "timing" ou "authority" ou "need" ou "competition",
        "timestamp": "MM:SS EXATO",
        "cliente_disse": "Cita√ß√£o EXATA",
        "vendedor_respondeu": "Cita√ß√£o EXATA",
        "rating": 1-10,
        "avaliacao": "An√°lise cr√≠tica",
        "como_deveria": "Script espec√≠fico de como deveria responder"
      }
    ]
  }
}

**IMPORTANTE:** Retorne APENAS o JSON, sem texto adicional antes ou depois.`;

// Chunking configuration
const CHUNK_SIZE = 25000; // ~25k characters per chunk
const CHUNK_OVERLAP = 2000; // overlap between chunks

interface ChunkAnalysis {
  scores: Record<string, number>;
  metodologia_chave_mestra?: any;
  perfil_lead_identificado?: any;
  sale_result?: {
    status: 'closed' | 'not_closed' | 'promise' | 'unknown';
    status_description: string;
    scheduled_date: string | null;
    scheduled_time: string | null;
    notes: string;
    next_steps: string;
    closing_moment?: {
      timestamp: string;
      quote: string;
      success: boolean;
    };
  };
  insights: {
    pontos_fortes: string[];
    pontos_fracos: string[];
    recomendacoes: string[];
    perfil_disc: any;
    timeline: any[];
    objecoes: any[];
  };
}

function splitIntoChunks(text: string): string[] {
  if (text.length <= CHUNK_SIZE) {
    return [text];
  }

  const chunks: string[] = [];
  let start = 0;

  while (start < text.length) {
    let end = start + CHUNK_SIZE;
    
    // Try to break at a natural point (newline or period)
    if (end < text.length) {
      const lastNewline = text.lastIndexOf('\n', end);
      const lastPeriod = text.lastIndexOf('. ', end);
      const breakPoint = Math.max(lastNewline, lastPeriod);
      
      if (breakPoint > start + CHUNK_SIZE / 2) {
        end = breakPoint + 1;
      }
    }

    chunks.push(text.slice(start, end));
    start = end - CHUNK_OVERLAP; // overlap
    
    // Prevent infinite loop
    if (start >= text.length - CHUNK_OVERLAP) {
      break;
    }
  }

  return chunks;
}

function consolidateAnalyses(analyses: ChunkAnalysis[]): ChunkAnalysis {
  if (analyses.length === 1) {
    return analyses[0];
  }

  // Average scores across all chunks
  const scoreKeys = ['conexao', 'spin_s', 'spin_p', 'spin_i', 'spin_n', 'apresentacao', 'fechamento', 'objecoes', 'compromisso_pagamento'];
  const avgScores: Record<string, number> = {};
  
  for (const key of scoreKeys) {
    const validScores = analyses.map(a => a.scores[key]).filter(s => typeof s === 'number');
    avgScores[key] = validScores.length > 0 
      ? Math.round(validScores.reduce((a, b) => a + b, 0) / validScores.length)
      : 0;
  }
  avgScores.global = Math.round(Object.values(avgScores).reduce((a, b) => a + b, 0) / scoreKeys.length);

  // Combine insights from all chunks
  const allPontosFortes = analyses.flatMap(a => a.insights.pontos_fortes || []);
  const allPontosFracos = analyses.flatMap(a => a.insights.pontos_fracos || []);
  const allRecomendacoes = analyses.flatMap(a => a.insights.recomendacoes || []);
  const allTimeline = analyses.flatMap(a => a.insights.timeline || []);
  const allObjecoes = analyses.flatMap(a => a.insights.objecoes || []);

  // Use the DISC profile from the first chunk (or aggregate if needed)
  const perfilDisc = analyses[0]?.insights.perfil_disc || null;
  
  // Use sale_result from the last chunk (most likely to contain closing info)
  const saleResult = analyses[analyses.length - 1]?.sale_result || analyses[0]?.sale_result || null;

  // Deduplicate and limit items
  const uniquePontosFortes = [...new Set(allPontosFortes)].slice(0, 10);
  const uniquePontosFracos = [...new Set(allPontosFracos)].slice(0, 10);
  const uniqueRecomendacoes = [...new Set(allRecomendacoes)].slice(0, 10);

  // Sort timeline by timestamp if possible
  const sortedTimeline = allTimeline.sort((a, b) => {
    const parseTime = (t: string) => {
      if (!t) return 0;
      const parts = t.split(':').map(Number);
      if (parts.length === 3) return parts[0] * 3600 + parts[1] * 60 + parts[2];
      if (parts.length === 2) return parts[0] * 60 + parts[1];
      return 0;
    };
    return parseTime(a.timestamp) - parseTime(b.timestamp);
  }).slice(0, 20);

  // Use metodologia_chave_mestra from the first chunk (most comprehensive analysis)
  const metodologiaChaveMestra = analyses[0]?.metodologia_chave_mestra || null;
  
  // Use perfil_lead_identificado from the first chunk
  const perfilLeadIdentificado = analyses[0]?.perfil_lead_identificado || null;

  return {
    scores: avgScores,
    metodologia_chave_mestra: metodologiaChaveMestra,
    perfil_lead_identificado: perfilLeadIdentificado,
    sale_result: saleResult || undefined,
    insights: {
      pontos_fortes: uniquePontosFortes,
      pontos_fracos: uniquePontosFracos,
      recomendacoes: uniqueRecomendacoes,
      perfil_disc: perfilDisc,
      timeline: sortedTimeline,
      objecoes: allObjecoes.slice(0, 10)
    }
  };
}

// Normalize timestamp to correct format (convert MM:SS where MM > 59 to HH:MM:SS)
function normalizeTimestamp(ts: string): string {
  if (!ts) return ts;
  
  const parts = ts.replace(/[\[\]]/g, '').split(':').map(Number);
  
  if (parts.length === 2) {
    const [mins, secs] = parts;
    // If minutes >= 60, convert to HH:MM:SS
    if (mins >= 60) {
      const hours = Math.floor(mins / 60);
      const remainingMins = mins % 60;
      return `${hours.toString().padStart(2, '0')}:${remainingMins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
    }
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  }
  
  if (parts.length === 3) {
    // Already in HH:MM:SS format, just normalize padding
    return `${parts[0].toString().padStart(2, '0')}:${parts[1].toString().padStart(2, '0')}:${parts[2].toString().padStart(2, '0')}`;
  }
  
  return ts;
}

// Validate and correct timestamps by matching quotes in the original transcription
function validateAndCorrectTimestamps(analysis: ChunkAnalysis, transcription: string): ChunkAnalysis {
  console.log('Starting timestamp validation and correction...');
  
  // Parse transcription into lines with timestamps
  // IMPORTANT: Support timestamps like 109:46 (more than 60 minutes)
  const lines = transcription.split('\n').filter(line => line.trim());
  const timestampedLines: { timestamp: string; text: string; fullLine: string }[] = [];
  
  for (const line of lines) {
    // Updated regex to support timestamps like 109:46 or 01:49:46
    const match = line.match(/^\[(\d{1,3}:\d{2}(?::\d{2})?)\]\s*(?:vendedor|cliente|speaker\s*\w*):\s*(.+)/i);
    if (match) {
      timestampedLines.push({
        timestamp: match[1],
        text: match[2].trim(),
        fullLine: line
      });
    }
  }
  
  console.log(`Parsed ${timestampedLines.length} timestamped lines from transcription`);
  
  // Normalize text for comparison - remove accents, punctuation, extra spaces
  const normalizeText = (text: string): string => {
    return text
      .toLowerCase()
      .normalize('NFD')
      .replace(/[\u0300-\u036f]/g, '') // Remove accents
      .replace(/[.,!?;:'"()\[\]{}]/g, '') // Remove punctuation
      .replace(/\s+/g, ' ')
      .trim();
  };
  
  // Get significant words from text (words with 3+ characters)
  const getSignificantWords = (text: string): string[] => {
    return normalizeText(text).split(' ').filter(w => w.length >= 3);
  };
  
  // Function to find the correct timestamp for a quote using robust matching
  function findCorrectTimestamp(quote: string): string | null {
    if (!quote || quote.length < 10) return null;
    
    const normalizedQuote = normalizeText(quote);
    const quoteWords = getSignificantWords(quote);
    
    console.log(`Searching for quote: "${quote.substring(0, 60)}..." (${quoteWords.length} significant words)`);
    
    let bestMatch: { timestamp: string; score: number; matchType: string } | null = null;
    
    for (const line of timestampedLines) {
      const normalizedLine = normalizeText(line.text);
      const lineWords = getSignificantWords(line.text);
      
      // Method 1: Exact match
      if (normalizedLine === normalizedQuote) {
        console.log(`Exact match found at ${line.timestamp}`);
        return line.timestamp;
      }
      
      // Method 2: Quote contained in line or vice versa
      if (normalizedLine.includes(normalizedQuote) || normalizedQuote.includes(normalizedLine)) {
        const score = Math.min(normalizedQuote.length, normalizedLine.length) / Math.max(normalizedQuote.length, normalizedLine.length);
        if (!bestMatch || score > bestMatch.score) {
          bestMatch = { timestamp: line.timestamp, score, matchType: 'contains' };
        }
      }
      
      // Method 3: Word overlap - use first 10 significant words for matching
      if (quoteWords.length >= 3) {
        const searchWords = quoteWords.slice(0, 10);
        let matchingWords = 0;
        
        for (const word of searchWords) {
          // Check if word exists in line (partial match allowed for longer words)
          if (lineWords.some(lw => lw === word || (word.length >= 5 && lw.includes(word)) || (word.length >= 5 && word.includes(lw)))) {
            matchingWords++;
          }
        }
        
        const matchRatio = matchingWords / searchWords.length;
        
        // If at least 60% of first 10 words match, this is likely the right line
        if (matchRatio >= 0.6) {
          // Weight longer matches higher
          const score = matchRatio + (matchingWords * 0.05);
          if (!bestMatch || score > bestMatch.score) {
            bestMatch = { timestamp: line.timestamp, score, matchType: `words(${matchingWords}/${searchWords.length})` };
          }
        }
      }
    }
    
    // Return if we have a good match
    if (bestMatch && bestMatch.score >= 0.5) {
      console.log(`Best match found: ${bestMatch.timestamp} (score: ${bestMatch.score.toFixed(2)}, type: ${bestMatch.matchType})`);
      return bestMatch.timestamp;
    }
    
    console.log(`No good match found for quote`);
    return null;
  }
  
  // Correct timeline timestamps and normalize format
  if (analysis.insights?.timeline) {
    let corrected = 0;
    analysis.insights.timeline = analysis.insights.timeline.map(item => {
      // First normalize the timestamp format
      if (item.timestamp) {
        const normalizedTs = normalizeTimestamp(item.timestamp);
        if (normalizedTs !== item.timestamp) {
          console.log(`Timeline format normalization: "${item.timestamp}" -> "${normalizedTs}"`);
          item.timestamp = normalizedTs;
        }
      }
      
      if (item.quote) {
        const correctTimestamp = findCorrectTimestamp(item.quote);
        if (correctTimestamp && correctTimestamp !== item.timestamp) {
          console.log(`Timeline correction: "${item.timestamp}" -> "${correctTimestamp}" for quote: "${item.quote.substring(0, 50)}..."`);
          corrected++;
          return { ...item, timestamp: correctTimestamp };
        }
      }
      return item;
    });
    console.log(`Corrected ${corrected} timeline timestamps`);
  }
  
  // Correct objections timestamps and normalize format
  if (analysis.insights?.objecoes) {
    let corrected = 0;
    analysis.insights.objecoes = analysis.insights.objecoes.map(item => {
      // First normalize the timestamp format
      if (item.timestamp) {
        const normalizedTs = normalizeTimestamp(item.timestamp);
        if (normalizedTs !== item.timestamp) {
          console.log(`Objection format normalization: "${item.timestamp}" -> "${normalizedTs}"`);
          item.timestamp = normalizedTs;
        }
      }
      
      // Try to find timestamp from cliente_disse first
      if (item.cliente_disse) {
        const correctTimestamp = findCorrectTimestamp(item.cliente_disse);
        if (correctTimestamp && correctTimestamp !== item.timestamp) {
          console.log(`Objection correction: "${item.timestamp}" -> "${correctTimestamp}" for quote: "${item.cliente_disse.substring(0, 50)}..."`);
          corrected++;
          return { ...item, timestamp: correctTimestamp };
        }
      }
      return item;
    });
    console.log(`Corrected ${corrected} objection timestamps`);
  }
  
  // Correct sale_result closing_moment timestamp if present
  if (analysis.sale_result?.closing_moment) {
    // First normalize the timestamp format
    if (analysis.sale_result.closing_moment.timestamp) {
      const normalizedTs = normalizeTimestamp(analysis.sale_result.closing_moment.timestamp);
      if (normalizedTs !== analysis.sale_result.closing_moment.timestamp) {
        console.log(`Closing moment format normalization: "${analysis.sale_result.closing_moment.timestamp}" -> "${normalizedTs}"`);
        analysis.sale_result.closing_moment.timestamp = normalizedTs;
      }
    }
    
    if (analysis.sale_result.closing_moment.quote) {
      const correctTimestamp = findCorrectTimestamp(analysis.sale_result.closing_moment.quote);
      if (correctTimestamp && correctTimestamp !== analysis.sale_result.closing_moment.timestamp) {
        console.log(`Closing moment correction: "${analysis.sale_result.closing_moment.timestamp}" -> "${correctTimestamp}"`);
        analysis.sale_result.closing_moment.timestamp = correctTimestamp;
      }
    }
  }
  
  return analysis;
}

// Robust JSON parsing with sanitization for GPT responses
function sanitizeAndParseJSON(text: string): any {
  // Step 1: Try direct parse
  try {
    return JSON.parse(text);
  } catch (e) {
    console.log('Direct JSON parse failed, attempting sanitization...');
  }

  // Step 2: Remove common issues that cause JSON parsing to fail
  let sanitized = text
    // Remove control characters except newlines and tabs
    .replace(/[\x00-\x08\x0B\x0C\x0E-\x1F]/g, '')
    // Fix unescaped newlines inside JSON string values
    .replace(/:\s*"([^"]*?)[\r\n]+([^"]*?)"/g, (match, p1, p2) => {
      return `: "${p1}\\n${p2}"`;
    })
    // Fix trailing commas before } or ]
    .replace(/,(\s*[}\]])/g, '$1')
    // Remove any BOM or zero-width characters
    .replace(/[\uFEFF\u200B-\u200D\u2060]/g, '');

  try {
    return JSON.parse(sanitized);
  } catch (e) {
    console.log('Sanitized parse failed, trying regex extraction...');
  }

  // Step 3: Try to extract just the JSON object with a more careful regex
  const jsonMatch = text.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    let extracted = jsonMatch[0]
      .replace(/[\x00-\x08\x0B\x0C\x0E-\x1F]/g, '')
      .replace(/,(\s*[}\]])/g, '$1');
    
    try {
      return JSON.parse(extracted);
    } catch (e) {
      console.log('Extracted JSON parse failed, trying line-by-line fix...');
    }

    // Step 4: Try to fix common issues in a more aggressive way
    // Replace problematic characters in string values
    extracted = extracted.replace(/"([^"]*?)"/g, (match, content) => {
      const fixed = content
        .replace(/\n/g, '\\n')
        .replace(/\r/g, '\\r')
        .replace(/\t/g, '\\t');
      return `"${fixed}"`;
    });

    try {
      return JSON.parse(extracted);
    } catch (e) {
      console.error('All JSON parsing attempts failed');
      throw new Error('Failed to parse AI response as valid JSON after multiple sanitization attempts');
    }
  }

  throw new Error('No JSON object found in AI response');
}

async function analyzeChunk(
  chunk: string, 
  chunkIndex: number, 
  totalChunks: number,
  openAIApiKey: string,
  durationInfo: string
): Promise<ChunkAnalysis> {
  const chunkContext = totalChunks > 1 
    ? `\n\n**NOTA**: Esta √© a parte ${chunkIndex + 1} de ${totalChunks} da transcri√ß√£o completa.`
    : '';

  let lastError: Error | null = null;
  const maxAttempts = 3;

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      console.log(`Analyzing chunk ${chunkIndex + 1}/${totalChunks} (${chunk.length} chars) - attempt ${attempt}/${maxAttempts}`);
      
      // Use lower temperature on retry to get more consistent JSON
      const temperature = attempt === 1 ? 0.3 : attempt === 2 ? 0.1 : 0;

      const aiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${openAIApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: ANALYSIS_PROMPT },
            { role: 'user', content: `Transcri√ß√£o da liga√ß√£o (formatada com timestamps [MM:SS] antes de cada fala):${durationInfo}${chunkContext}\n\n${chunk}` }
          ],
          temperature,
          response_format: { type: "json_object" }, // Force valid JSON output
        }),
      });

      if (!aiResponse.ok) {
        const errorText = await aiResponse.text();
        console.error(`OpenAI API error (attempt ${attempt}):`, errorText);
        throw new Error(`OpenAI API error: ${errorText}`);
      }

      const aiData = await aiResponse.json();
      const responseText = aiData.choices[0].message.content;

      // Log response length for debugging
      console.log(`Received AI response (attempt ${attempt}): ${responseText.length} chars`);

      // With response_format: json_object, the response should be valid JSON
      // But still try to extract and sanitize just in case
      let jsonToParse = responseText;
      
      // Try to extract JSON object if response has extra content
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        jsonToParse = jsonMatch[0];
      }

      // Use robust JSON parsing with sanitization
      const parsed = sanitizeAndParseJSON(jsonToParse);
      console.log(`Successfully parsed JSON for chunk ${chunkIndex + 1} on attempt ${attempt}`);
      return parsed;

    } catch (error: any) {
      lastError = error;
      console.error(`Chunk ${chunkIndex + 1} attempt ${attempt}/${maxAttempts} failed: ${error.message}`);
      
      if (attempt < maxAttempts) {
        const delay = attempt * 2000; // Increasing delay: 2s, 4s
        console.log(`Retrying chunk ${chunkIndex + 1} in ${delay/1000}s with lower temperature...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  throw lastError || new Error(`Analysis failed for chunk ${chunkIndex + 1} after ${maxAttempts} attempts`);
}

Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  // Check for internal key authentication (from webhook)
  const internalKey = req.headers.get('x-internal-key');
  const expectedKey = Deno.env.get('INTERNAL_FUNCTION_KEY');
  
  const isInternalAuth = internalKey && expectedKey && internalKey === expectedKey;

  if (!isInternalAuth) {
    // Fall back to regular user authentication
    try {
      const auth = await requireAuth(req);
      if (!auth.user) {
        return new Response(JSON.stringify({ error: 'Unauthorized' }), {
          status: 401,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    } catch (_e) {
      return new Response(JSON.stringify({ error: 'Unauthorized' }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }
  } else {
    console.log('Authenticated via internal key (webhook call)');
  }

  let videoId: string | undefined;

  try {
    const body = await req.json();
    const { transcription, transcriptionId } = body;
    videoId = body.videoId;

    if (!transcription || !videoId) {
      throw new Error('transcription and videoId are required');
    }

    console.log(`Analyzing transcription for video: ${videoId} (${transcription.length} chars)`);

    // Get video duration from database
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseKey);

    const { data: videoData, error: videoError } = await supabase
      .from('videos')
      .select('duration_sec')
      .eq('id', videoId)
      .single();

    if (videoError) {
      console.error('Error fetching video duration:', videoError);
    }

    const durationInfo = videoData?.duration_sec 
      ? `\n\n**INFORMA√á√ÉO IMPORTANTE:** A dura√ß√£o total desta grava√ß√£o √© de ${Math.floor(videoData.duration_sec / 60)} minutos e ${videoData.duration_sec % 60} segundos (${videoData.duration_sec}s total). Todos os timestamps na sua an√°lise devem estar dentro deste intervalo.`
      : '';

    const openAIApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openAIApiKey) {
      throw new Error('OPENAI_API_KEY not configured');
    }

    const startTime = Date.now();
    
    // Split transcription into chunks if needed
    const chunks = splitIntoChunks(transcription);
    console.log(`Transcription split into ${chunks.length} chunk(s)`);

    // Analyze all chunks
    const chunkAnalyses: ChunkAnalysis[] = [];
    for (let i = 0; i < chunks.length; i++) {
      const analysis = await analyzeChunk(chunks[i], i, chunks.length, openAIApiKey, durationInfo);
      chunkAnalyses.push(analysis);
    }

    // Consolidate all chunk analyses
    let analysisData = consolidateAnalyses(chunkAnalyses);
    
    // Validate and correct timestamps by matching quotes in the transcription
    console.log('Validating and correcting timestamps...');
    analysisData = validateAndCorrectTimestamps(analysisData, transcription);
    
    const processingTime = Math.round((Date.now() - startTime) / 1000);

    console.log(`Analysis complete with validated timestamps. Processing time: ${processingTime}s`);

    // Prepare sale result data for database
    const saleResult = analysisData.sale_result;
    let scheduledDate: string | null = null;
    if (saleResult?.scheduled_date) {
      try {
        // Try to parse the date - could be in various formats
        const dateStr = saleResult.scheduled_date;
        if (dateStr.match(/^\d{4}-\d{2}-\d{2}/)) {
          scheduledDate = dateStr;
        } else {
          // Try to create a date object
          const parsed = new Date(dateStr);
          if (!isNaN(parsed.getTime())) {
            scheduledDate = parsed.toISOString();
          }
        }
      } catch (e) {
        console.log('Could not parse scheduled date:', saleResult.scheduled_date);
      }
    }

    // Save analysis to database
    const { data: analysisRecord, error: analysisError } = await supabase
      .from('analyses')
      .insert({
        video_id: videoId,
        score_global: analysisData.scores.global,
        score_conexao: analysisData.scores.conexao,
        score_spin_s: analysisData.scores.spin_s,
        score_spin_p: analysisData.scores.spin_p,
        score_spin_i: analysisData.scores.spin_i,
        score_spin_n: analysisData.scores.spin_n,
        score_apresentacao: analysisData.scores.apresentacao,
        score_fechamento: analysisData.scores.fechamento,
        score_objecoes: analysisData.scores.objecoes,
        score_compromisso_pagamento: analysisData.scores.compromisso_pagamento,
        model: 'gpt-4o-mini',
        processing_time_sec: processingTime,
        insights_json: { 
          ...analysisData.insights, 
          sale_result: saleResult,
          metodologia_chave_mestra: analysisData.metodologia_chave_mestra,
          perfil_lead_identificado: analysisData.perfil_lead_identificado
        },
        sale_status: saleResult?.status || 'unknown',
        scheduled_date: scheduledDate,
        sale_notes: saleResult?.notes || null,
      })
      .select()
      .single();

    if (analysisError) {
      throw new Error(`Failed to save analysis: ${analysisError.message}`);
    }

    // Update video status to completed
    const { error: updateError } = await supabase
      .from('videos')
      .update({ status: 'completed' })
      .eq('id', videoId);

    if (updateError) {
      console.error('Failed to update video status:', updateError);
    }

    console.log(`Analysis saved: ${analysisRecord.id}`);

    return new Response(
      JSON.stringify({
        success: true,
        analysis: analysisRecord,
        insights: analysisData.insights,
        chunksProcessed: chunks.length
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error: any) {
    console.error('Error in analyze-transcription:', error);
    
    // Extract clean error message
    let errorMessage = error.message || 'Erro desconhecido na an√°lise';
    
    // ALWAYS update video status to failed when there's an error
    if (videoId) {
      const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
      const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
      const supabase = createClient(supabaseUrl, supabaseKey);
      
      console.log(`Updating video ${videoId} status to failed with error: ${errorMessage}`);
      
      const { error: updateError } = await supabase
        .from('videos')
        .update({ 
          status: 'failed',
          error_message: errorMessage 
        })
        .eq('id', videoId);
      
      if (updateError) {
        console.error('Failed to update video status:', updateError);
      } else {
        console.log('Video status successfully updated to failed');
      }
    } else {
      console.error('CRITICAL: No videoId available to update status in analyze-transcription');
    }
    
    return new Response(
      JSON.stringify({ error: errorMessage }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});
