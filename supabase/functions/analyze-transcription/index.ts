import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.76.1';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

async function requireAuth(req: Request) {
  const authHeader = req.headers.get('authorization') || req.headers.get('Authorization') || '';
  if (!authHeader.toLowerCase().startsWith('bearer ')) {
    return { user: null, error: 'missing_auth' as const };
  }

  const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
  const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
  const authClient = createClient(supabaseUrl, serviceRoleKey, {
    global: { headers: { Authorization: authHeader } },
  });

  const { data, error } = await authClient.auth.getUser();
  if (error || !data?.user) {
    return { user: null, error: 'invalid_auth' as const };
  }

  return { user: data.user, error: null };
}


const ANALYSIS_PROMPT = `Voc√™ √© um especialista em an√°lise de vendas usando a metodologia SPIN Selling e perfis comportamentais DISC.

Analise a transcri√ß√£o da liga√ß√£o de vendas abaixo e forne√ßa uma an√°lise DETALHADA E FIDEDIGNA baseada APENAS no que realmente aconteceu na conversa.

**üö® REGRA CR√çTICA ABSOLUTA PARA TIMESTAMPS (LEIA COM ATEN√á√ÉO):**

A transcri√ß√£o est√° formatada assim:
[MM:SS] speaker: texto da fala

VOC√ä DEVE SEGUIR ESTAS REGRAS SEM EXCE√á√ÉO:

1. **EXTRA√á√ÉO DO TIMESTAMP**: O timestamp que voc√™ usar DEVE ser copiado EXATAMENTE da MESMA LINHA onde a cita√ß√£o aparece
2. **VALIDA√á√ÉO OBRIGAT√ìRIA**: Antes de colocar um timestamp, CONFIRME que a cita√ß√£o est√° NAQUELA LINHA
3. **EXEMPLO CORRETO**: Se na transcri√ß√£o est√°:
   [58:03] vendedor: O que funciona √© consultoria, √© acompanhamento.
   
   Ent√£o: timestamp = "58:03" e quote = "O que funciona √© consultoria, √© acompanhamento."
   
4. **EXEMPLO ERRADO**: N√ÉO pegue o timestamp de uma linha e a cita√ß√£o de outra linha
5. **NUNCA APROXIME**: Se a cita√ß√£o est√° em [58:03], o timestamp DEVE ser exatamente "58:03", NUNCA "56:24" ou "58:00"
6. **FORMATO**: Use MM:SS ou HH:MM:SS (sem colchetes, sem milissegundos)
7. **ORDEM CRONOL√ìGICA**: Mantenha ESTRITAMENTE a ordem dos eventos como aparecem na transcri√ß√£o
8. **CITA√á√ÉO EXATA**: Copie a cita√ß√£o LITERALMENTE como aparece na transcri√ß√£o

**VERIFICA√á√ÉO FINAL**: Para cada item da timeline e obje√ß√µes, verifique:
- A cita√ß√£o aparece EXATAMENTE ap√≥s o timestamp [XX:XX] que voc√™ especificou?
- Se n√£o, corrija o timestamp para o correto

- **SIL√äNCIO INICIAL**: Se a primeira fala est√° em [03:00], significa que houve 3 minutos de sil√™ncio/introdu√ß√£o antes
- Cite APENAS frases que REALMENTE foram ditas (copie exatamente, incluindo contexto suficiente)
- **CONTEXTO CORRETO**: Se mencionar uma frase espec√≠fica na an√°lise (campo "why"), ela DEVE estar presente na cita√ß√£o (campo "quote")
- N√ÉO invente nomes de pessoas se n√£o estiverem mencionados
- N√ÉO invente momentos que n√£o aconteceram
- Se n√£o houver informa√ß√£o suficiente para um crit√©rio, seja honesto e d√™ score baixo

**PERFIS COMPORTAMENTAIS DISC:**

üü• **DOMINANTE (D)** - "Eu quero resultado, e quero agora"
Caracter√≠sticas do cliente:
- Fala r√°pido, direto ao ponto, pouco tolerante a rodeios
- Foca em resultados, ROI, performance, impacto, lideran√ßa
- Usa linguagem assertiva, toma decis√µes rapidamente
- Evita perda de tempo, explica√ß√µes longas, superficialidade
- Perguntas sobre efici√™ncia e resultados
- Palavras-chave: resultado, ganho, velocidade, efici√™ncia, lideran√ßa, poder

Comunica√ß√£o CORRETA do vendedor para perfil D:
‚úÖ Ser direto, objetivo, sem rodeios
‚úÖ Falar de ROI, tempo economizado, resultados concretos
‚úÖ Mostrar n√∫meros, metas, performance
‚úÖ Ser assertivo e confiante
‚úÖ Ir direto ao ponto, economizar tempo
‚ùå EVITAR: explica√ß√µes longas, papo emocional, superficialidade, enrola√ß√£o

üü® **INFLUENTE (I)** - "Eu quero me sentir parte, me conectar"
Caracter√≠sticas do cliente:
- Fala com entusiasmo e emo√ß√£o, usa hist√≥rias e exemplos
- Soci√°vel, expressivo, foca em relacionamentos
- Linguagem positiva e animada
- Busca reconhecimento, pertencimento, visibilidade
- Evita frieza, ambientes secos, rigidez
- Palavras-chave: inspira√ß√£o, comunidade, conex√£o, alegria, pertencimento

Comunica√ß√£o CORRETA do vendedor para perfil I:
‚úÖ Criar conex√£o emocional, acolhimento
‚úÖ Contar hist√≥rias e usar exemplos inspiradores
‚úÖ Mostrar comunidade, pertencimento
‚úÖ Ser entusiasmado, positivo, expressivo
‚úÖ Validar emo√ß√µes e criar v√≠nculo
‚ùå EVITAR: tom frio, linguagem t√©cnica seca, distanciamento, rigidez

üü© **EST√ÅVEL (S)** - "Eu preciso me sentir seguro e acolhido"
Caracter√≠sticas do cliente:
- Fala pausadamente e calmamente
- Busca seguran√ßa, estabilidade, processos claros
- Evita conflitos, press√£o, mudan√ßas bruscas
- Faz perguntas sobre implementa√ß√£o
- Precisa de tempo para decidir
- Palavras-chave: seguran√ßa, processo, apoio, estabilidade, previsibilidade

Comunica√ß√£o CORRETA do vendedor para perfil S:
‚úÖ Mostrar processo passo a passo
‚úÖ Criar seguran√ßa, sem press√£o
‚úÖ Oferecer suporte cont√≠nuo
‚úÖ Empatia, calma, acolhimento
‚úÖ Dar tempo para refletir
‚ùå EVITAR: urg√™ncia agressiva, press√£o, mudan√ßa brusca, linguagem de ruptura

üü¶ **CONFORME (C)** - "Eu s√≥ acredito se tiver l√≥gica e dados"
Caracter√≠sticas do cliente:
- Foca em dados, detalhes t√©cnicos, precis√£o
- Faz muitas perguntas espec√≠ficas
- Linguagem precisa e formal
- Quer provas, evid√™ncias, compara√ß√µes
- Anal√≠tico e cauteloso
- Palavras-chave: an√°lise, dados, m√©todo, l√≥gica, estrutura, detalhamento

Comunica√ß√£o CORRETA do vendedor para perfil C:
‚úÖ Apresentar dados, m√©tricas, provas
‚úÖ Mostrar comparativos t√©cnicos
‚úÖ Estrutura clara, metodologia validada
‚úÖ Responder com precis√£o e l√≥gica
‚úÖ Oferecer documenta√ß√£o e detalhes
‚ùå EVITAR: improviso, frases vagas, apelos emocionais sem l√≥gica, falta de estrutura

**CRIT√âRIOS DE AVALIA√á√ÉO:**

1. **Conex√£o (0-100)**: Rapport, empatia, constru√ß√£o de relacionamento
   - Avalie se o vendedor criou conex√£o emocional
   - Usou o nome do cliente? Demonstrou interesse genu√≠no?
   - Encontrou pontos em comum?

2. **SPIN - Situa√ß√£o (0-100)**: Perguntas sobre a situa√ß√£o atual do cliente
   - Quantas perguntas de situa√ß√£o foram feitas?
   - Foram abertas e explorat√≥rias?
   - O vendedor entendeu o contexto antes de vender?

3. **SPIN - Problema (0-100)**: Identifica√ß√£o de problemas e desafios
   - O vendedor identificou dores reais?
   - Fez o cliente verbalizar os problemas?
   - Foi al√©m da superf√≠cie?

4. **SPIN - Implica√ß√£o (0-100)**: Explora√ß√£o das consequ√™ncias dos problemas
   - O vendedor explorou o custo de n√£o resolver?
   - Criou urg√™ncia genu√≠na?
   - Fez o cliente sentir o problema?

5. **SPIN - Necessidade (0-100)**: Desenvolvimento da necessidade de solu√ß√£o
   - O cliente chegou sozinho √† conclus√£o que precisa da solu√ß√£o?
   - O vendedor conduziu para que o cliente se vendesse?

6. **Apresenta√ß√£o (0-100)**: Clareza e relev√¢ncia da apresenta√ß√£o da solu√ß√£o
   - Apresentou apenas AP√ìS entender as dores?
   - Conectou features com os problemas identificados?
   - Foi claro e objetivo?

7. **Fechamento (0-100)**: Condu√ß√£o para pr√≥ximos passos
   - Conduziu naturalmente para o fechamento?
   - Pediu a venda ou pr√≥ximo passo?
   - Foi assertivo?

8. **Obje√ß√µes (0-100)**: Tratamento de obje√ß√µes e d√∫vidas
   - Como tratou as obje√ß√µes?
   - Usou t√©cnicas adequadas?
   - Transformou obje√ß√µes em oportunidades?

9. **Compromisso/Pagamento (0-100)**: Discuss√£o sobre investimento
   - Como apresentou o valor?
   - Tratou como investimento ou custo?
   - Criou percep√ß√£o de valor antes de falar de pre√ßo?

**FORMATO DE RESPOSTA (JSON V√ÅLIDO):**
{
  "scores": {
    "conexao": n√∫mero 0-100,
    "spin_s": n√∫mero 0-100,
    "spin_p": n√∫mero 0-100,
    "spin_i": n√∫mero 0-100,
    "spin_n": n√∫mero 0-100,
    "apresentacao": n√∫mero 0-100,
    "fechamento": n√∫mero 0-100,
    "objecoes": n√∫mero 0-100,
    "compromisso_pagamento": n√∫mero 0-100,
    "global": (m√©dia dos scores acima)
  },
  "sale_result": {
    "status": "closed" ou "not_closed" ou "promise" ou "unknown",
    "status_description": "Descri√ß√£o clara do resultado: 'Venda fechada', 'Venda n√£o fechada', 'Promessa de venda agendada', ou 'N√£o foi poss√≠vel identificar'",
    "scheduled_date": "Data agendada no formato YYYY-MM-DD se houver promessa de follow-up, reuni√£o ou fechamento marcado. null se n√£o houver.",
    "scheduled_time": "Hor√°rio agendado se mencionado, no formato HH:MM. null se n√£o houver.",
    "notes": "Detalhes importantes sobre o fechamento ou n√£o fechamento. Cite exatamente o que foi dito sobre compromisso, pr√≥ximos passos, ou motivo de n√£o fechar.",
    "next_steps": "O que foi combinado como pr√≥ximo passo entre vendedor e cliente",
    "closing_moment": {
      "timestamp": "Timestamp [MM:SS] do momento de fechamento ou tentativa de fechamento",
      "quote": "Cita√ß√£o exata do momento de fechamento ou tentativa",
      "success": true ou false
    }
  },
  "insights": {
    "pontos_fortes": [
      "Descreva especificamente o que o vendedor fez bem, citando momentos reais"
    ],
    "pontos_fracos": [
      "Descreva especificamente o que precisa melhorar, citando o que faltou"
    ],
    "recomendacoes": [
      "A√ß√µes espec√≠ficas e pr√°ticas para melhorar, baseadas nos pontos fracos. NUNCA recomende acelerar o ritmo, reduzir a dura√ß√£o da call ou falar mais r√°pido. Foque em t√©cnicas de vendas, abordagem e comunica√ß√£o."
    ],
    "perfil_disc": {
      "perfil_dominante": "D" ou "I" ou "S" ou "C",
      "perfil_nome": "Dominante" ou "Influente" ou "Est√°vel" ou "Conforme",
      "emoji": "üü•" ou "üü®" ou "üü©" ou "üü¶",
      "descricao": "Descri√ß√£o curta do perfil identificado",
      "percentuais": {
        "D": n√∫mero 0-100,
        "I": n√∫mero 0-100,
        "S": n√∫mero 0-100,
        "C": n√∫mero 0-100
      },
      "caracteristicas_identificadas": [
        "Lista de caracter√≠sticas espec√≠ficas observadas na fala do CLIENTE que indicam este perfil"
      ],
      "comunicacao_vendedor": {
        "adequada": true ou false,
        "score_adequacao": n√∫mero 0-100,
        "analise": "An√°lise detalhada se o vendedor est√° comunicando de forma adequada para este perfil",
        "pontos_positivos": [
          "Aspectos CORRETOS na comunica√ß√£o do vendedor para este perfil, citando momentos espec√≠ficos"
        ],
        "pontos_melhorar": [
          "Aspectos que N√ÉO se adequam ao perfil, citando momentos espec√≠ficos onde o vendedor errou a abordagem"
        ]
      },
      "recomendacoes_abordagem": [
        "Como o vendedor deve melhorar a comunica√ß√£o especificamente para este perfil DISC"
      ],
      "objecoes_previstas": [
        "Obje√ß√µes t√≠picas que este perfil pode apresentar"
      ],
      "estrategia_fechamento": "Como o vendedor deve fechar a venda especificamente para este perfil"
    },
    "timeline": [
      {
        "timestamp": "OBRIGAT√ìRIO: Use o timestamp EXATO que aparece entre colchetes [MM:SS] na transcri√ß√£o. Copie exatamente sem os colchetes.",
        "type": "positive" ou "negative",
        "title": "T√≠tulo curto e descritivo do momento (m√°x 60 caracteres)",
        "quote": "CITA√á√ÉO EXATA e COMPLETA da fala - copie literalmente pelo menos 2-3 frases do contexto. Esta cita√ß√£o DEVE conter todas as frases mencionadas no campo 'why'.",
        "speaker": "vendedor" ou "cliente" (use exatamente esses termos em min√∫sculas)",
        "why": "Explica√ß√£o ESPEC√çFICA e DETALHADA do porqu√™ esse momento foi bom ou ruim (m√≠nimo 50 palavras). CR√çTICO: Se mencionar frases espec√≠ficas aqui, elas DEVEM aparecer no campo 'quote'. Mantenha a ordem cronol√≥gica EXATA dos eventos como aparecem na transcri√ß√£o.",
        "fix": "Como corrigir (APENAS para momentos negativos) - seja espec√≠fico, pr√°tico e detalhado (m√≠nimo 50 palavras)"
      }
    ],
    "objecoes": [
      {
        "type": "price" ou "timing" ou "authority" ou "need" ou "competition",
        "timestamp": "TIMESTAMP REAL que aparece entre colchetes [MM:SS] onde a obje√ß√£o aconteceu",
        "cliente_disse": "CITA√á√ÉO EXATA do que o cliente disse",
        "vendedor_respondeu": "CITA√á√ÉO EXATA da resposta do vendedor",
        "rating": n√∫mero de 1 a 10 (qu√£o bem o vendedor tratou),
        "avaliacao": "An√°lise cr√≠tica: o que foi bom e o que foi ruim na resposta",
        "como_deveria": "Script espec√≠fico de como deveria ter respondido - seja pr√°tico e aplic√°vel"
      }
    ]
  }
}

**IMPORTANTE:** Retorne APENAS o JSON, sem texto adicional antes ou depois.`;

// Chunking configuration
const CHUNK_SIZE = 25000; // ~25k characters per chunk
const CHUNK_OVERLAP = 2000; // overlap between chunks

interface ChunkAnalysis {
  scores: Record<string, number>;
  sale_result?: {
    status: 'closed' | 'not_closed' | 'promise' | 'unknown';
    status_description: string;
    scheduled_date: string | null;
    scheduled_time: string | null;
    notes: string;
    next_steps: string;
    closing_moment?: {
      timestamp: string;
      quote: string;
      success: boolean;
    };
  };
  insights: {
    pontos_fortes: string[];
    pontos_fracos: string[];
    recomendacoes: string[];
    perfil_disc: any;
    timeline: any[];
    objecoes: any[];
  };
}

function splitIntoChunks(text: string): string[] {
  if (text.length <= CHUNK_SIZE) {
    return [text];
  }

  const chunks: string[] = [];
  let start = 0;

  while (start < text.length) {
    let end = start + CHUNK_SIZE;
    
    // Try to break at a natural point (newline or period)
    if (end < text.length) {
      const lastNewline = text.lastIndexOf('\n', end);
      const lastPeriod = text.lastIndexOf('. ', end);
      const breakPoint = Math.max(lastNewline, lastPeriod);
      
      if (breakPoint > start + CHUNK_SIZE / 2) {
        end = breakPoint + 1;
      }
    }

    chunks.push(text.slice(start, end));
    start = end - CHUNK_OVERLAP; // overlap
    
    // Prevent infinite loop
    if (start >= text.length - CHUNK_OVERLAP) {
      break;
    }
  }

  return chunks;
}

function consolidateAnalyses(analyses: ChunkAnalysis[]): ChunkAnalysis {
  if (analyses.length === 1) {
    return analyses[0];
  }

  // Average scores across all chunks
  const scoreKeys = ['conexao', 'spin_s', 'spin_p', 'spin_i', 'spin_n', 'apresentacao', 'fechamento', 'objecoes', 'compromisso_pagamento'];
  const avgScores: Record<string, number> = {};
  
  for (const key of scoreKeys) {
    const validScores = analyses.map(a => a.scores[key]).filter(s => typeof s === 'number');
    avgScores[key] = validScores.length > 0 
      ? Math.round(validScores.reduce((a, b) => a + b, 0) / validScores.length)
      : 0;
  }
  avgScores.global = Math.round(Object.values(avgScores).reduce((a, b) => a + b, 0) / scoreKeys.length);

  // Combine insights from all chunks
  const allPontosFortes = analyses.flatMap(a => a.insights.pontos_fortes || []);
  const allPontosFracos = analyses.flatMap(a => a.insights.pontos_fracos || []);
  const allRecomendacoes = analyses.flatMap(a => a.insights.recomendacoes || []);
  const allTimeline = analyses.flatMap(a => a.insights.timeline || []);
  const allObjecoes = analyses.flatMap(a => a.insights.objecoes || []);

  // Use the DISC profile from the first chunk (or aggregate if needed)
  const perfilDisc = analyses[0]?.insights.perfil_disc || null;
  
  // Use sale_result from the last chunk (most likely to contain closing info)
  const saleResult = analyses[analyses.length - 1]?.sale_result || analyses[0]?.sale_result || null;

  // Deduplicate and limit items
  const uniquePontosFortes = [...new Set(allPontosFortes)].slice(0, 10);
  const uniquePontosFracos = [...new Set(allPontosFracos)].slice(0, 10);
  const uniqueRecomendacoes = [...new Set(allRecomendacoes)].slice(0, 10);

  // Sort timeline by timestamp if possible
  const sortedTimeline = allTimeline.sort((a, b) => {
    const parseTime = (t: string) => {
      if (!t) return 0;
      const parts = t.split(':').map(Number);
      if (parts.length === 3) return parts[0] * 3600 + parts[1] * 60 + parts[2];
      if (parts.length === 2) return parts[0] * 60 + parts[1];
      return 0;
    };
    return parseTime(a.timestamp) - parseTime(b.timestamp);
  }).slice(0, 20);

  return {
    scores: avgScores,
    sale_result: saleResult || undefined,
    insights: {
      pontos_fortes: uniquePontosFortes,
      pontos_fracos: uniquePontosFracos,
      recomendacoes: uniqueRecomendacoes,
      perfil_disc: perfilDisc,
      timeline: sortedTimeline,
      objecoes: allObjecoes.slice(0, 10)
    }
  };
}

// Normalize timestamp to correct format (convert MM:SS where MM > 59 to HH:MM:SS)
function normalizeTimestamp(ts: string): string {
  if (!ts) return ts;
  
  const parts = ts.replace(/[\[\]]/g, '').split(':').map(Number);
  
  if (parts.length === 2) {
    const [mins, secs] = parts;
    // If minutes >= 60, convert to HH:MM:SS
    if (mins >= 60) {
      const hours = Math.floor(mins / 60);
      const remainingMins = mins % 60;
      return `${hours.toString().padStart(2, '0')}:${remainingMins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
    }
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  }
  
  if (parts.length === 3) {
    // Already in HH:MM:SS format, just normalize padding
    return `${parts[0].toString().padStart(2, '0')}:${parts[1].toString().padStart(2, '0')}:${parts[2].toString().padStart(2, '0')}`;
  }
  
  return ts;
}

// Validate and correct timestamps by matching quotes in the original transcription
function validateAndCorrectTimestamps(analysis: ChunkAnalysis, transcription: string): ChunkAnalysis {
  console.log('Starting timestamp validation and correction...');
  
  // Parse transcription into lines with timestamps
  const lines = transcription.split('\n').filter(line => line.trim());
  const timestampedLines: { timestamp: string; text: string; fullLine: string }[] = [];
  
  for (const line of lines) {
    const match = line.match(/^\[(\d{1,2}:\d{2}(?::\d{2})?)\]\s*(?:vendedor|cliente|speaker\s*\w*):\s*(.+)/i);
    if (match) {
      timestampedLines.push({
        timestamp: match[1],
        text: match[2].trim(),
        fullLine: line
      });
    }
  }
  
  console.log(`Parsed ${timestampedLines.length} timestamped lines from transcription`);
  
  // Function to find the correct timestamp for a quote
  function findCorrectTimestamp(quote: string): string | null {
    if (!quote || quote.length < 10) return null;
    
    // Normalize the quote for comparison
    const normalizeText = (text: string) => text.toLowerCase().replace(/[.,!?;:'"]/g, '').replace(/\s+/g, ' ').trim();
    const normalizedQuote = normalizeText(quote);
    
    // Try to find exact or partial match
    let bestMatch: { timestamp: string; score: number } | null = null;
    
    for (const line of timestampedLines) {
      const normalizedLine = normalizeText(line.text);
      
      // Check for exact match
      if (normalizedLine === normalizedQuote) {
        return line.timestamp;
      }
      
      // Check if quote is contained in line or vice versa
      if (normalizedLine.includes(normalizedQuote) || normalizedQuote.includes(normalizedLine)) {
        const score = Math.min(normalizedQuote.length, normalizedLine.length) / Math.max(normalizedQuote.length, normalizedLine.length);
        if (!bestMatch || score > bestMatch.score) {
          bestMatch = { timestamp: line.timestamp, score };
        }
      }
      
      // Check for significant word overlap (at least 50% of words match)
      const quoteWords = normalizedQuote.split(' ').filter(w => w.length > 3);
      const lineWords = normalizedLine.split(' ').filter(w => w.length > 3);
      
      if (quoteWords.length >= 3) {
        const matchingWords = quoteWords.filter(word => lineWords.includes(word));
        const matchRatio = matchingWords.length / quoteWords.length;
        
        if (matchRatio >= 0.5) {
          const score = matchRatio;
          if (!bestMatch || score > bestMatch.score) {
            bestMatch = { timestamp: line.timestamp, score };
          }
        }
      }
    }
    
    // Only return if we have a good match (score > 0.4)
    if (bestMatch && bestMatch.score > 0.4) {
      return bestMatch.timestamp;
    }
    
    return null;
  }
  
  // Correct timeline timestamps and normalize format
  if (analysis.insights?.timeline) {
    let corrected = 0;
    analysis.insights.timeline = analysis.insights.timeline.map(item => {
      // First normalize the timestamp format
      if (item.timestamp) {
        const normalizedTs = normalizeTimestamp(item.timestamp);
        if (normalizedTs !== item.timestamp) {
          console.log(`Timeline format normalization: "${item.timestamp}" -> "${normalizedTs}"`);
          item.timestamp = normalizedTs;
        }
      }
      
      if (item.quote) {
        const correctTimestamp = findCorrectTimestamp(item.quote);
        if (correctTimestamp && correctTimestamp !== item.timestamp) {
          console.log(`Timeline correction: "${item.timestamp}" -> "${correctTimestamp}" for quote: "${item.quote.substring(0, 50)}..."`);
          corrected++;
          return { ...item, timestamp: correctTimestamp };
        }
      }
      return item;
    });
    console.log(`Corrected ${corrected} timeline timestamps`);
  }
  
  // Correct objections timestamps and normalize format
  if (analysis.insights?.objecoes) {
    let corrected = 0;
    analysis.insights.objecoes = analysis.insights.objecoes.map(item => {
      // First normalize the timestamp format
      if (item.timestamp) {
        const normalizedTs = normalizeTimestamp(item.timestamp);
        if (normalizedTs !== item.timestamp) {
          console.log(`Objection format normalization: "${item.timestamp}" -> "${normalizedTs}"`);
          item.timestamp = normalizedTs;
        }
      }
      
      // Try to find timestamp from cliente_disse first
      if (item.cliente_disse) {
        const correctTimestamp = findCorrectTimestamp(item.cliente_disse);
        if (correctTimestamp && correctTimestamp !== item.timestamp) {
          console.log(`Objection correction: "${item.timestamp}" -> "${correctTimestamp}" for quote: "${item.cliente_disse.substring(0, 50)}..."`);
          corrected++;
          return { ...item, timestamp: correctTimestamp };
        }
      }
      return item;
    });
    console.log(`Corrected ${corrected} objection timestamps`);
  }
  
  // Correct sale_result closing_moment timestamp if present
  if (analysis.sale_result?.closing_moment) {
    // First normalize the timestamp format
    if (analysis.sale_result.closing_moment.timestamp) {
      const normalizedTs = normalizeTimestamp(analysis.sale_result.closing_moment.timestamp);
      if (normalizedTs !== analysis.sale_result.closing_moment.timestamp) {
        console.log(`Closing moment format normalization: "${analysis.sale_result.closing_moment.timestamp}" -> "${normalizedTs}"`);
        analysis.sale_result.closing_moment.timestamp = normalizedTs;
      }
    }
    
    if (analysis.sale_result.closing_moment.quote) {
      const correctTimestamp = findCorrectTimestamp(analysis.sale_result.closing_moment.quote);
      if (correctTimestamp && correctTimestamp !== analysis.sale_result.closing_moment.timestamp) {
        console.log(`Closing moment correction: "${analysis.sale_result.closing_moment.timestamp}" -> "${correctTimestamp}"`);
        analysis.sale_result.closing_moment.timestamp = correctTimestamp;
      }
    }
  }
  
  return analysis;
}

// Robust JSON parsing with sanitization for GPT responses
function sanitizeAndParseJSON(text: string): any {
  // Step 1: Try direct parse
  try {
    return JSON.parse(text);
  } catch (e) {
    console.log('Direct JSON parse failed, attempting sanitization...');
  }

  // Step 2: Remove common issues that cause JSON parsing to fail
  let sanitized = text
    // Remove control characters except newlines and tabs
    .replace(/[\x00-\x08\x0B\x0C\x0E-\x1F]/g, '')
    // Fix unescaped newlines inside JSON string values
    .replace(/:\s*"([^"]*?)[\r\n]+([^"]*?)"/g, (match, p1, p2) => {
      return `: "${p1}\\n${p2}"`;
    })
    // Fix trailing commas before } or ]
    .replace(/,(\s*[}\]])/g, '$1')
    // Remove any BOM or zero-width characters
    .replace(/[\uFEFF\u200B-\u200D\u2060]/g, '');

  try {
    return JSON.parse(sanitized);
  } catch (e) {
    console.log('Sanitized parse failed, trying regex extraction...');
  }

  // Step 3: Try to extract just the JSON object with a more careful regex
  const jsonMatch = text.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    let extracted = jsonMatch[0]
      .replace(/[\x00-\x08\x0B\x0C\x0E-\x1F]/g, '')
      .replace(/,(\s*[}\]])/g, '$1');
    
    try {
      return JSON.parse(extracted);
    } catch (e) {
      console.log('Extracted JSON parse failed, trying line-by-line fix...');
    }

    // Step 4: Try to fix common issues in a more aggressive way
    // Replace problematic characters in string values
    extracted = extracted.replace(/"([^"]*?)"/g, (match, content) => {
      const fixed = content
        .replace(/\n/g, '\\n')
        .replace(/\r/g, '\\r')
        .replace(/\t/g, '\\t');
      return `"${fixed}"`;
    });

    try {
      return JSON.parse(extracted);
    } catch (e) {
      console.error('All JSON parsing attempts failed');
      throw new Error('Failed to parse AI response as valid JSON after multiple sanitization attempts');
    }
  }

  throw new Error('No JSON object found in AI response');
}

async function analyzeChunk(
  chunk: string, 
  chunkIndex: number, 
  totalChunks: number,
  openAIApiKey: string,
  durationInfo: string
): Promise<ChunkAnalysis> {
  const chunkContext = totalChunks > 1 
    ? `\n\n**NOTA**: Esta √© a parte ${chunkIndex + 1} de ${totalChunks} da transcri√ß√£o completa.`
    : '';

  let lastError: Error | null = null;
  const maxAttempts = 3;

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      console.log(`Analyzing chunk ${chunkIndex + 1}/${totalChunks} (${chunk.length} chars) - attempt ${attempt}/${maxAttempts}`);
      
      // Use lower temperature on retry to get more consistent JSON
      const temperature = attempt === 1 ? 0.3 : attempt === 2 ? 0.1 : 0;

      const aiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${openAIApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: ANALYSIS_PROMPT },
            { role: 'user', content: `Transcri√ß√£o da liga√ß√£o (formatada com timestamps [MM:SS] antes de cada fala):${durationInfo}${chunkContext}\n\n${chunk}` }
          ],
          temperature,
          response_format: { type: "json_object" }, // Force valid JSON output
        }),
      });

      if (!aiResponse.ok) {
        const errorText = await aiResponse.text();
        console.error(`OpenAI API error (attempt ${attempt}):`, errorText);
        throw new Error(`OpenAI API error: ${errorText}`);
      }

      const aiData = await aiResponse.json();
      const responseText = aiData.choices[0].message.content;

      // Log response length for debugging
      console.log(`Received AI response (attempt ${attempt}): ${responseText.length} chars`);

      // With response_format: json_object, the response should be valid JSON
      // But still try to extract and sanitize just in case
      let jsonToParse = responseText;
      
      // Try to extract JSON object if response has extra content
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        jsonToParse = jsonMatch[0];
      }

      // Use robust JSON parsing with sanitization
      const parsed = sanitizeAndParseJSON(jsonToParse);
      console.log(`Successfully parsed JSON for chunk ${chunkIndex + 1} on attempt ${attempt}`);
      return parsed;

    } catch (error: any) {
      lastError = error;
      console.error(`Chunk ${chunkIndex + 1} attempt ${attempt}/${maxAttempts} failed: ${error.message}`);
      
      if (attempt < maxAttempts) {
        const delay = attempt * 2000; // Increasing delay: 2s, 4s
        console.log(`Retrying chunk ${chunkIndex + 1} in ${delay/1000}s with lower temperature...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  throw lastError || new Error(`Analysis failed for chunk ${chunkIndex + 1} after ${maxAttempts} attempts`);
}

Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  // Check for internal key authentication (from webhook)
  const internalKey = req.headers.get('x-internal-key');
  const expectedKey = Deno.env.get('INTERNAL_FUNCTION_KEY');
  
  const isInternalAuth = internalKey && expectedKey && internalKey === expectedKey;

  if (!isInternalAuth) {
    // Fall back to regular user authentication
    try {
      const auth = await requireAuth(req);
      if (!auth.user) {
        return new Response(JSON.stringify({ error: 'Unauthorized' }), {
          status: 401,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    } catch (_e) {
      return new Response(JSON.stringify({ error: 'Unauthorized' }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }
  } else {
    console.log('Authenticated via internal key (webhook call)');
  }

  let videoId: string | undefined;

  try {
    const body = await req.json();
    const { transcription, transcriptionId } = body;
    videoId = body.videoId;

    if (!transcription || !videoId) {
      throw new Error('transcription and videoId are required');
    }

    console.log(`Analyzing transcription for video: ${videoId} (${transcription.length} chars)`);

    // Get video duration from database
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseKey);

    const { data: videoData, error: videoError } = await supabase
      .from('videos')
      .select('duration_sec')
      .eq('id', videoId)
      .single();

    if (videoError) {
      console.error('Error fetching video duration:', videoError);
    }

    const durationInfo = videoData?.duration_sec 
      ? `\n\n**INFORMA√á√ÉO IMPORTANTE:** A dura√ß√£o total desta grava√ß√£o √© de ${Math.floor(videoData.duration_sec / 60)} minutos e ${videoData.duration_sec % 60} segundos (${videoData.duration_sec}s total). Todos os timestamps na sua an√°lise devem estar dentro deste intervalo.`
      : '';

    const openAIApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openAIApiKey) {
      throw new Error('OPENAI_API_KEY not configured');
    }

    const startTime = Date.now();
    
    // Split transcription into chunks if needed
    const chunks = splitIntoChunks(transcription);
    console.log(`Transcription split into ${chunks.length} chunk(s)`);

    // Analyze all chunks
    const chunkAnalyses: ChunkAnalysis[] = [];
    for (let i = 0; i < chunks.length; i++) {
      const analysis = await analyzeChunk(chunks[i], i, chunks.length, openAIApiKey, durationInfo);
      chunkAnalyses.push(analysis);
    }

    // Consolidate all chunk analyses
    let analysisData = consolidateAnalyses(chunkAnalyses);
    
    // Validate and correct timestamps by matching quotes in the transcription
    console.log('Validating and correcting timestamps...');
    analysisData = validateAndCorrectTimestamps(analysisData, transcription);
    
    const processingTime = Math.round((Date.now() - startTime) / 1000);

    console.log(`Analysis complete with validated timestamps. Processing time: ${processingTime}s`);

    // Prepare sale result data for database
    const saleResult = analysisData.sale_result;
    let scheduledDate: string | null = null;
    if (saleResult?.scheduled_date) {
      try {
        // Try to parse the date - could be in various formats
        const dateStr = saleResult.scheduled_date;
        if (dateStr.match(/^\d{4}-\d{2}-\d{2}/)) {
          scheduledDate = dateStr;
        } else {
          // Try to create a date object
          const parsed = new Date(dateStr);
          if (!isNaN(parsed.getTime())) {
            scheduledDate = parsed.toISOString();
          }
        }
      } catch (e) {
        console.log('Could not parse scheduled date:', saleResult.scheduled_date);
      }
    }

    // Save analysis to database
    const { data: analysisRecord, error: analysisError } = await supabase
      .from('analyses')
      .insert({
        video_id: videoId,
        score_global: analysisData.scores.global,
        score_conexao: analysisData.scores.conexao,
        score_spin_s: analysisData.scores.spin_s,
        score_spin_p: analysisData.scores.spin_p,
        score_spin_i: analysisData.scores.spin_i,
        score_spin_n: analysisData.scores.spin_n,
        score_apresentacao: analysisData.scores.apresentacao,
        score_fechamento: analysisData.scores.fechamento,
        score_objecoes: analysisData.scores.objecoes,
        score_compromisso_pagamento: analysisData.scores.compromisso_pagamento,
        model: 'gpt-4o-mini',
        processing_time_sec: processingTime,
        insights_json: { ...analysisData.insights, sale_result: saleResult },
        sale_status: saleResult?.status || 'unknown',
        scheduled_date: scheduledDate,
        sale_notes: saleResult?.notes || null,
      })
      .select()
      .single();

    if (analysisError) {
      throw new Error(`Failed to save analysis: ${analysisError.message}`);
    }

    // Update video status to completed
    const { error: updateError } = await supabase
      .from('videos')
      .update({ status: 'completed' })
      .eq('id', videoId);

    if (updateError) {
      console.error('Failed to update video status:', updateError);
    }

    console.log(`Analysis saved: ${analysisRecord.id}`);

    return new Response(
      JSON.stringify({
        success: true,
        analysis: analysisRecord,
        insights: analysisData.insights,
        chunksProcessed: chunks.length
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error: any) {
    console.error('Error in analyze-transcription:', error);
    
    // Extract clean error message
    let errorMessage = error.message || 'Erro desconhecido na an√°lise';
    
    // ALWAYS update video status to failed when there's an error
    if (videoId) {
      const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
      const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
      const supabase = createClient(supabaseUrl, supabaseKey);
      
      console.log(`Updating video ${videoId} status to failed with error: ${errorMessage}`);
      
      const { error: updateError } = await supabase
        .from('videos')
        .update({ 
          status: 'failed',
          error_message: errorMessage 
        })
        .eq('id', videoId);
      
      if (updateError) {
        console.error('Failed to update video status:', updateError);
      } else {
        console.log('Video status successfully updated to failed');
      }
    } else {
      console.error('CRITICAL: No videoId available to update status in analyze-transcription');
    }
    
    return new Response(
      JSON.stringify({ error: errorMessage }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});
